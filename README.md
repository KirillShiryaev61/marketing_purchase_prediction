# Проект: "Будут ли они покупать?" — Бинарная классификация для маркетинга

**Описание проекта:**

Интернет-магазин собирает историю покупателей, проводит рассылки предложений и планирует будущие продажи. Для оптимизации процессов надо выделить пользователей, которые готовы совершить покупку в ближайшее время.

**Цель проекта** — Предсказать вероятность покупки в течение `90 дней`.

**Ход исследования:**

- `Подготовка данных`: загрузка и изучение общей информации из представленных датасетов.


- `Предобработка данных и агрегирование признаков:`: агрегирование признаков для обучения моделей из сырых данных.


- `Исследовательский анализ данных`: изучение признаков, их распределение, поиск выбросов/аномалий в данных.


- `Корреляционный анализ`: изучение взимосвязей между входными признаками и целевыми, а также и между ними.


- `Использование пайплайнов`: написание пайплайнов для подготовки данных и обучения модели для упрощения и ускорения поиска лучшей модели и ее гиперпараметров.


- `Поиск лучшей модели`: грубый поиск лучших гиперпараметров с помощью `GridSearchCV`, поиск оптимального набора признака для моделей с помощью `RFECV`, более точный поиск лучших гиперпараметров и обучение моделей с помощью `BayesSearchCV`, обучение ансамблевой модели с применением `soft-voting`, тестирование итоговой модели и анализ результатов.


- `Анализ важности признаков`: анализ степени важности признаков их влияния на принятие решений моделью с помощью метода `SHAP`.


- `Общий вывод`: резюмирование полученных результатов, формулировка ключевых выводов и рекомендаций.


**Результаты работы:**

Была обучена ансамблевая модель бинарной классификации с алгоритмом `soft_voting`, где каждая базовая модель обучена на индивидуальном наборе признаков полученный с помощью `RFECV`, а дисбаланс классов был обработан с помощью указания `class_weight=balanced` в гиперпараметрах базовых моделей. Модель была выбрана благодаря стабильности её качества (стандартное отклонение `ROC-AUC` на кросс-валидации `≈ 0.0078`), не смотря на то, что показывает сопоставимое качество с отдельными моделями `LightGBM` и `CatBoost`.

**Метрики ансамблевой модели:**

- Precision (тест): `0.0526`
- Recall (тест): `0.6458`
- PR-AUC (тест): `0.1033`
- ROC_AUC (тест): `0.7649`

**Обобщение и рекомендации:**

Модель улавливает слабый, но реальный сигнал: её `PR-AUC (0.103)` примерно **в 5 раз выше**, чем у случайной модели (ожидаемый `baseline ≈ 0.02` при доле положительного класса **2%**).

Модель успешно находит **64%** всех истинных положительных клиентов (`Recall = 0.645`), однако почти все её предсказания положительного класса ошибочны: лишь **5.2%** из клиентов, помеченных как класс `1`, действительно принадлежат этому классу (`Precision = 0.052`), что типично при сильном дисбалансе классов.

Несмотря на низкую точность, такой результат — хорошая отправная точка. Для улучшения качества необходимо: 

- Оптимизировать модель по метрике `PR-AUC` (`Average Precision`);
- Более детально подойти к подбору весов для классов, провести эксперименты для улучшения результата;
- При необходимости — применить техники балансировки выборки.

**Технологии:**

- **Data Processing**: `numpy`, `pandas`;
- **Visualization**: `matplotlib`, `seaborn`;
- **ML & Preprocessing**: `scikit-learn`, `skope`, `lightgbm`, `catboost`;
- **Statistical Analysis**: `scipy`, `statsmodels` (VIF, тесты нормальности);
- **Correlation Analysis**: `phik` — для анализа связей между числовыми и категориальными признаками;
- **Model Interpretation**: `shap` — объяснение предсказаний моделей.